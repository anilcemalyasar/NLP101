{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415b1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from textblob import Word, TextBlob\n",
    "import re\n",
    "from string import punctuation\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdbea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62f5a8",
   "metadata": {},
   "source": [
    "###  Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d26862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>total_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3SBTW3WS4IQSN</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1406073600</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18K1ODH1I2MVB</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>0mie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>MOAR SPACE!!!</td>\n",
       "      <td>1382659200</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2FII3I2MBMUIA</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1K3</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>nothing to really say....</td>\n",
       "      <td>1356220800</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3H99DFEG68SR</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1m2</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Great buy at this price!!!  *** UPDATE</td>\n",
       "      <td>1384992000</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A375ZM4U047O79</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>2&amp;amp;1/2Men</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>best deal around</td>\n",
       "      <td>1373673600</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  reviewerName helpful                                         reviewText  overall                                 summary  unixReviewTime  reviewTime  day_diff  \\\n",
       "0  A3SBTW3WS4IQSN  B007WTAJTO           NaN  [0, 0]                                         No issues.     4.00                              Four Stars      1406073600  2014-07-23       138   \n",
       "1  A18K1ODH1I2MVB  B007WTAJTO          0mie  [0, 0]  Purchased this for my device, it worked as adv...     5.00                           MOAR SPACE!!!      1382659200  2013-10-25       409   \n",
       "2  A2FII3I2MBMUIA  B007WTAJTO           1K3  [0, 0]  it works as expected. I should have sprung for...     4.00               nothing to really say....      1356220800  2012-12-23       715   \n",
       "3   A3H99DFEG68SR  B007WTAJTO           1m2  [0, 0]  This think has worked out great.Had a diff. br...     5.00  Great buy at this price!!!  *** UPDATE      1384992000  2013-11-21       382   \n",
       "4  A375ZM4U047O79  B007WTAJTO  2&amp;1/2Men  [0, 0]  Bought it with Retail Packaging, arrived legit...     5.00                        best deal around      1373673600  2013-07-13       513   \n",
       "\n",
       "   helpful_yes  total_vote  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/amazon_reviews.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Normalizing Case Folding\n",
    "###############################\n",
    "df[\"reviewText\"] = df[\"reviewText\"].astype(\"str\").apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445d8854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              no issues.\n",
       "1       purchased this for my device, it worked as adv...\n",
       "2       it works as expected. i should have sprung for...\n",
       "3       this think has worked out great.had a diff. br...\n",
       "4       bought it with retail packaging, arrived legit...\n",
       "                              ...                        \n",
       "4910    i bought this sandisk 16gb class 10 to use wit...\n",
       "4911    used this for extending the capabilities of my...\n",
       "4912    great card that is very fast and reliable. it ...\n",
       "4913    good amount of space for the stuff i want to d...\n",
       "4914    i've heard bad things about this 64gb micro sd...\n",
       "Name: reviewText, Length: 4915, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d831bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Punctuations\n",
    "###############################\n",
    "def remove_punctuations(text):\n",
    "    new_text = []\n",
    "    for word in text.split():  # metni kelimelere ayır\n",
    "        w = re.sub(r'[^\\w\\s]', '', word)  # Noktalama işaretlerini kaldır\n",
    "        w = re.sub(r'_', '', w)  # Alt çizgiyi kaldır\n",
    "        new_text.append(w)  # Düzenlenen kelimeyi listeye ekle\n",
    "    \n",
    "    return \" \".join(new_text)  # Listeyi string olarak birleştir\n",
    "\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a664883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               no issues\n",
       "1       purchased this for my device it worked as adve...\n",
       "2       it works as expected i should have sprung for ...\n",
       "3       this think has worked out greathad a diff bran...\n",
       "4       bought it with retail packaging arrived legit ...\n",
       "                              ...                        \n",
       "4910    i bought this sandisk 16gb class 10 to use wit...\n",
       "4911    used this for extending the capabilities of my...\n",
       "4912    great card that is very fast and reliable it c...\n",
       "4913    good amount of space for the stuff i want to d...\n",
       "4914    ive heard bad things about this 64gb micro sd ...\n",
       "Name: reviewText, Length: 4915, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d002771",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Numbers\n",
    "###############################\n",
    "df['reviewText'] = df['reviewText'].str.replace(r'\\d', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00545bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               no issues\n",
       "1       purchased this for my device it worked as adve...\n",
       "2       it works as expected i should have sprung for ...\n",
       "3       this think has worked out greathad a diff bran...\n",
       "4       bought it with retail packaging arrived legit ...\n",
       "                              ...                        \n",
       "4910    i bought this sandisk gb class  to use with my...\n",
       "4911    used this for extending the capabilities of my...\n",
       "4912    great card that is very fast and reliable it c...\n",
       "4913    good amount of space for the stuff i want to d...\n",
       "4914    ive heard bad things about this gb micro sd ca...\n",
       "Name: reviewText, Length: 4915, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5bdc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "# Stopwords\n",
    "###############################\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d13e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5855e3bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  issues\n",
       "1       purchased device worked advertised never much ...\n",
       "2       works expected sprung higher capacity think ma...\n",
       "3       think worked greathad diff bran gb card went s...\n",
       "4       bought retail packaging arrived legit orange e...\n",
       "                              ...                        \n",
       "4910    bought sandisk gb class use htc inspire months...\n",
       "4911    used extending capabilities samsung galaxy not...\n",
       "4912    great card fast reliable comes optional adapte...\n",
       "4913          good amount space stuff want fits gopro say\n",
       "4914    ive heard bad things gb micro sd card crapping...\n",
       "Name: reviewText, Length: 4915, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: \" \".join(x for x in str(x).split() if x not in sw))\n",
    "df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a253bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Lemmatization\n",
    "###############################\n",
    "nltk.download(\"wordnet\")\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faccedc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   issue\n",
       "1       purchased device worked advertised never much ...\n",
       "2       work expected sprung higher capacity think mad...\n",
       "3       think worked greathad diff bran gb card went s...\n",
       "4       bought retail packaging arrived legit orange e...\n",
       "                              ...                        \n",
       "4910    bought sandisk gb class use htc inspire month ...\n",
       "4911    used extending capability samsung galaxy note ...\n",
       "4912    great card fast reliable come optional adapter...\n",
       "4913           good amount space stuff want fit gopro say\n",
       "4914    ive heard bad thing gb micro sd card crapping ...\n",
       "Name: reviewText, Length: 4915, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5082eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Lemmatization\n",
    "###############################\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3248fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating | eat\n",
      "ate | ate\n",
      "eat | eat\n",
      "eats | eat\n",
      "adjustable | adjust\n",
      "ability | abil\n",
      "rafting | raft\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"Eating\", \"ate\", \"eat\", \"eats\", \"adjustable\", \"ability\", \"rafting\", \"meeting\"]\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf0e3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "ability | ability\n",
      "adjustable | adjustable\n",
      "rafting | rafting\n",
      "meeting | meeting\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"eating eats eat ate ability adjustable rafting meeting\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, '|', token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
